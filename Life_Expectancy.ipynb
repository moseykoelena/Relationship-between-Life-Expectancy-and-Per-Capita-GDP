    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoUq1Fj1B02h"
      },
      "source": [
        "### Part 4: Classification Report\n",
        "\n",
        "In this section I will accomplish evaluating a classification model by using precision and recall metrics that can be used to convey how well the model performs on observations in specific classes. In order to do this first I define two possible classes: positive class and negative class. \n",
        "Then I group the observations: true positive if it was predicted to be in the positive class, and actually was in the positive class, false positive if it was predicted to be in the positive class, but actually was in the negative class, true negative if it was predicted to be in the negative class, and actually was in the negative class, false negative if it was predicted to be in the negative class, but actually was in the positive class. Then based on these observations I define positive precision, positive recall, negative precision, and negative recall scores. \n",
        "Finally I will display reports of 2 classification models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TVTXtegB02i"
      },
      "outputs": [],
      "source": [
        "def classification_report(true_y, pred_y): \n",
        "    classes=numpy.unique(true_y)\n",
        "    acc=find_accuracy(true_y, pred_y)\n",
        "    pos=classes[1]\n",
        "    neg=classes[0]\n",
        "    TP=numpy.sum((pred_y==classes[1])&(true_y==classes[1]))\n",
        "    FP=numpy.sum((pred_y==classes[1])&(true_y==classes[0]))\n",
        "    TN=numpy.sum((pred_y==classes[0])&(true_y==classes[0]))\n",
        "    FN=numpy.sum((pred_y==classes[0])&(true_y==classes[1]))\n",
        "    pos_prec=TP/(TP+FP)\n",
        "    pos_rec=TP/(TP+FN)\n",
        "    neg_prec=TN/(TN+FN)\n",
        "    neg_rec=TN/(TN+FP)\n",
        "    print('Positive Class:      ',pos)\n",
        "    print('Negative Class:      ',neg)\n",
        "    print('                     ')\n",
        "    print('Accuracy:            ',acc)\n",
        "    print('Positive Precision:  ',round(pos_prec,4))\n",
        "    print('Positive Recall:     ',round(pos_rec,4))\n",
        "    print('Negative Precision:  ',round(neg_prec,4))\n",
        "    print('Negative Recall:     ',round(neg_rec,4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrtbpC30B02i",
        "outputId": "98b601fc-22b0-429f-c278-90ab9dee03e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positive Class:       P\n",
            "Negative Class:       N\n",
            "                     \n",
            "Accuracy:             0.75\n",
            "Positive Precision:   0.5556\n",
            "Positive Recall:      0.8333\n",
            "Negative Precision:   0.9091\n",
            "Negative Recall:      0.7143\n"
          ]
        }
      ],
      "source": [
        "classification_report(true_diag,pred_diag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0lNJxd0B02i",
        "outputId": "04e4dcb4-ae5d-48a5-ddc1-22b13ef99b07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positive Class:       dog\n",
            "Negative Class:       cat\n",
            "                     \n",
            "Accuracy:             0.875\n",
            "Positive Precision:   0.8333\n",
            "Positive Recall:      0.9091\n",
            "Negative Precision:   0.9167\n",
            "Negative Recall:      0.8462\n"
          ]
        }
      ],
      "source": [
        "classification_report(true_labels,pred_labels)"
      ]
    },
    
